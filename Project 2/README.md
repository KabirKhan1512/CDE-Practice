# âœˆï¸ Flight Data ETL Pipeline (Pakistan's All Airlines)

This project builds a **serverless ETL pipeline** to fetch, process, and store flight data of Pakistanâ€™s airlines using the [AviationStack API](https://aviationstack.com/), AWS, and Snowflake.

It is my **first end-to-end data engineering project** after completing my training with **Sir Qasim and Ayan at SMIT**.

---

## ğŸ“Œ Project Overview

The pipeline automates the following steps:

1. **Extract** flight data of major Pakistani airlines (PIA, Airsial, SereneAir, Fly Jinnah, Airblue) from the AviationStack API.
2. **Store Raw Data** into AWS S3 in JSON format, partitioned by date and airline.
3. **Transform** raw JSON into clean CSVs using AWS Lambda and **Pandas**:
   - Flatten nested JSON.
   - Drop unnecessary fields (e.g., live data, aircraft details).
   - Convert timestamps into proper datetime format.
   - Append airline metadata (IATA code, airline name).
4. **Save Processed Data** back to S3 as both:
   - Per-airline CSV files.
   - A combined file containing all airlines for the day.
5. **Load into Snowflake**:
   - A **star schema** with **3 dimensions** (Airline, Airport, Flight) and **1 fact table (Flight Performance)**.
6. **Visualize** the processed data in **Power BI** (in progress).

---

## ğŸ–¼ï¸ Project Flow

### ğŸ”¹ ETL Flow

![Flow Diagram](flow.jpeg)

### ğŸ”¹ Snowflake Schema

![Snowflake Schema](schema.jpeg)

---

## âš™ï¸ Tech Stack

- **AWS Lambda** â€“ ETL orchestration
- **AWS S3** â€“ Data lake (raw + processed zones)
- **Python (Pandas, Boto3, urllib3)** â€“ Data processing and API integration
- **Snowflake** â€“ Data warehouse with star schema
- **Power BI** â€“ Visualization and analysis (ongoing)
- **AWS Secrets Manager** â€“ Secure storage for API keys and sensitive credentials

---
